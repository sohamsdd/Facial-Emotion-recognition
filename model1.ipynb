{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ccdf85cb",
   "metadata": {},
   "source": [
    "Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b090d312",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data analysis and visualisation libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "#to call the img files\n",
    "import os\n",
    "\n",
    "# Importing Deep Learning Libraries\n",
    "\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense,Input,Dropout,GlobalAveragePooling2D,Flatten,Conv2D,BatchNormalization,Activation,MaxPooling2D\n",
    "from keras.models import Model,Sequential\n",
    "#from keras.optimizers import Adam,SGD,RMSprop\n",
    "from tensorflow.keras.optimizers import Adam,SGD,RMSprop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5637206e",
   "metadata": {},
   "source": [
    "Displaying Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8807d0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#standardise picture size\n",
    "picture_size = 48\n",
    "folder_path = \"../input/face-expression-recognition-dataset/images/\"\n",
    "\n",
    "expression = 'disgust'\n",
    "\n",
    "plt.figure(figsize= (12,12))\n",
    "for i in range(1, 10, 1):\n",
    "    plt.subplot(3,3,i)\n",
    "    img = load_img(folder_path+\"train/\"+expression+\"/\"+\n",
    "                  os.listdir(folder_path + \"train/\" + expression)[i], target_size=(picture_size, picture_size))\n",
    "    plt.imshow(img)   \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0cfd105",
   "metadata": {},
   "source": [
    "Making Training and Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbfa385",
   "metadata": {},
   "outputs": [],
   "source": [
    "#batch size:How many training example your model should take in one iteration\n",
    "batch_size  = 128\n",
    "\n",
    "datagen_train  = ImageDataGenerator()\n",
    "datagen_val = ImageDataGenerator()\n",
    "\n",
    "train_set = datagen_train.flow_from_directory(folder_path+\"train\",\n",
    "                                              target_size = (picture_size,picture_size),\n",
    "                                              color_mode = \"grayscale\",\n",
    "                                              batch_size=batch_size,\n",
    "                                              class_mode='categorical',\n",
    "                                              shuffle=True)\n",
    "\n",
    "\n",
    "test_set = datagen_val.flow_from_directory(folder_path+\"validation\",\n",
    "                                              target_size = (picture_size,picture_size),\n",
    "                                              color_mode = \"grayscale\",\n",
    "                                              batch_size=batch_size,\n",
    "                                              class_mode='categorical',\n",
    "                                              shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7456a304",
   "metadata": {},
   "source": [
    "Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b84c720",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from keras.optimizers import Adam,SGD,RMSprop\n",
    "\n",
    "#7 Outcomes\n",
    "no_of_classes = 7\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "#ANN Layers:input Layer,dropout layer,flatten L,activation L,hidden L,...\n",
    "#1st CNN layer\n",
    "model.add(Conv2D(64,(3,3),padding = 'same',input_shape = (48,48,1)))\n",
    "#64:filters,(3,3):kernel size, (48,48):shape, 1:grayscale\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "#2nd CNN layer\n",
    "model.add(Conv2D(128,(5,5),padding = 'same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "model.add(Dropout (0.25))\n",
    "\n",
    "#3rd CNN layer\n",
    "model.add(Conv2D(512,(3,3),padding = 'same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "model.add(Dropout (0.25))\n",
    "\n",
    "#4th CNN layer\n",
    "model.add(Conv2D(512,(3,3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "#flatten(): collapse the i/p size to 1D array\n",
    "model.add(Flatten())\n",
    "\n",
    "#Fully connected 1st layer\n",
    "model.add(Dense(256))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "# Fully connected layer 2nd layer\n",
    "model.add(Dense(512))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Dense(no_of_classes, activation='softmax'))\n",
    "\n",
    "\n",
    "\n",
    "opt = Adam(lr = 0.0001)\n",
    "model.compile(optimizer=opt,loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be599a47",
   "metadata": {},
   "source": [
    "Fitting the Model with Training and Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c0bcd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath=\"./model.h5\", monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss',\n",
    "                          min_delta=0,\n",
    "                          patience=3,\n",
    "                          verbose=1,\n",
    "                          restore_best_weights=True\n",
    "                          )\n",
    "\n",
    "reduce_learningrate = ReduceLROnPlateau(monitor='val_loss',\n",
    "                              factor=0.2,\n",
    "                              patience=3,\n",
    "                              verbose=1,\n",
    "                              min_delta=0.0001)\n",
    "\n",
    "callbacks_list = [early_stopping,checkpoint,reduce_learningrate]\n",
    "\n",
    "epochs = 3\n",
    "#epochs = 48\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer = Adam(lr=0.001),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7d2792",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit_generator(generator=train_set,\n",
    "                                steps_per_epoch=train_set.n//train_set.batch_size,\n",
    "                                epochs=epochs,\n",
    "                                validation_data = test_set,\n",
    "                                validation_steps = test_set.n//test_set.batch_size,\n",
    "                                callbacks=callbacks_list\n",
    "                                )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01df9e4",
   "metadata": {},
   "source": [
    "Plotting Accuracy & Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11aa13bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('dark_background')\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.suptitle('Optimizer : Adam', fontsize=10)\n",
    "plt.ylabel('Loss', fontsize=16)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.ylabel('Accuracy', fontsize=16)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
